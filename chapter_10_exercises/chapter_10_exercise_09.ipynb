{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLP - Chapter 10 - Exercise 9\n",
    "### Author: pzuehlke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the lab, using an $ AR(5) $ model we need to predict the log volume $ v_t $\n",
    "on day $ t $ using a linear function of $ 5 $ lagged values of three features,\n",
    "namely: `log_volume` itself, `DJ_return` and `log_volatility`. Thus, our model will\n",
    "have a total of $ 15 $ predictors, plus an intercept.\n",
    "\n",
    "Note that in this exercise no neural networks are involved, despite it being in\n",
    "chapter $ 10 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones = load_data(\"NYSE\")\n",
    "dow_jones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataframe with all needed features, add the lag structure and\n",
    "extract month information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"DJ_return\", \"log_volume\", \"log_volatility\"]\n",
    "data = dow_jones[cols].copy()\n",
    "\n",
    "lag = 5\n",
    "for i in range(1, lag + 1):\n",
    "    for col in cols:\n",
    "        data[f\"{col}_{i}\"] = data[col].shift(i)\n",
    "data = data.dropna()\n",
    "\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data[\"month\"] = data.index.month  # 1 = January, 12 = December\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are time series data, we'll use a chronological split as recommended\n",
    "in the text.  More precisely, we choose the split so that test data consists of\n",
    "dates on or after January $ 2 $, $ 1980 $ (see Figure $ 10.14 $, p. $ 421 $)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"1980-01-02\")\n",
    "train_data = data[data.index < cutoff_date]\n",
    "test_data  = data[data.index >= cutoff_date]\n",
    "\n",
    "y_train = train_data[\"log_volume\"]\n",
    "y_test = test_data[\"log_volume\"]\n",
    "\n",
    "# Create feature matrix X with lag features only:\n",
    "lag_cols = [f\"{col}_{i}\" for i in range(1, lag + 1) for col in cols]\n",
    "X_train = train_data[lag_cols]\n",
    "X_test = test_data[lag_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to build our first autoregressive model (not including the\n",
    "month):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar5_model = LinearRegression()\n",
    "ar5_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ar5_model.predict(X_train)\n",
    "y_test_pred = ar5_model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"AR(5) with three predictors\\nTrain MSE: {train_mse:.4e},\\tTest MSE: {test_mse:.4e}\")\n",
    "print(f\"Test R^2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our base model has a test $ R^2 $ of $ 41.29\\% $, exactly as in the book (p. $\n",
    "461 $).  Now we do the same for the model including `month` to see if the\n",
    "situation improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")  # drop January to avoid collinearity\n",
    "month_train = encoder.fit_transform(train_data[[\"month\"]])\n",
    "month_test = encoder.transform(test_data[[\"month\"]])\n",
    "\n",
    "month_names = [f\"month_{i + 2}\" for i in range(11)]  # 2-12, since January was dropped\n",
    "\n",
    "X_train_month = np.hstack((X_train, month_train))\n",
    "X_test_month = np.hstack((X_test, month_test))\n",
    "\n",
    "X_train_month_df = pd.DataFrame(\n",
    "    X_train_month,\n",
    "    columns=X_train.columns.tolist() + month_names,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_month_df = pd.DataFrame(\n",
    "    X_test_month,\n",
    "    columns=X_test.columns.tolist() + month_names,\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar5_month_model = LinearRegression()\n",
    "ar5_month_model.fit(X_train_month_df, y_train)\n",
    "\n",
    "y_train_pred_month = ar5_month_model.predict(X_train_month_df)\n",
    "y_test_pred_month = ar5_month_model.predict(X_test_month_df)\n",
    "\n",
    "train_mse_month = mean_squared_error(y_train, y_train_pred_month)\n",
    "test_mse_month = mean_squared_error(y_test, y_test_pred_month)\n",
    "r2_month = r2_score(y_test, y_test_pred_month)\n",
    "print(\"AR(5) model with month dummy variables\"\n",
    "      f\"\\nTrain MSE: {train_mse_month:.4e},\\tTest MSE: {test_mse_month:.4e}\")\n",
    "print(f\"Test R^2: {r2_month:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's test $ R^2 $ has improved by only $ 0.4\\% $\n",
    "when compared to our base model.  Therefore (to answer the question in the\n",
    "statement), adding a categorical variable representing the month to the lag-$ 5\n",
    "$ autoregressive model does not seem to improve performance.\n",
    "\n",
    "Let's visualize the actual and predicted returns using both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(test_data.index, y_test, label=\"Actual\", color=\"black\", alpha=0.5)\n",
    "ax.plot(test_data.index, y_test_pred,\n",
    "        label=\"$ AR(5) $ prediction\", color=\"blue\", alpha=0.7)\n",
    "ax.plot(test_data.index, y_test_pred_month,\n",
    "        label=\"$ AR(5) $ with month prediction\", color=\"red\", alpha=0.7)\n",
    "ax.set_title(\"Dow Jones log volume: actual vs predicted\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Log volume\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make a residual plot for each of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_base = y_test - y_test_pred\n",
    "residuals_month = y_test - y_test_pred_month\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "ax1.scatter(y_test_pred, residuals_base, alpha=0.5, facecolor=\"none\", edgecolor=\"royalblue\")\n",
    "ax1.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "ax1.set_xlabel(\"Predicted values - $ AR(5) $\")\n",
    "ax1.set_ylabel(\"Residuals\")\n",
    "ax1.set_title(\"Residuals vs predicted values - $ AR(5) $\")\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(y_test_pred_month, residuals_month, alpha=0.5, facecolor=\"none\", edgecolor=\"royalblue\")\n",
    "ax2.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Predicted values - $ AR(5) $ with month\")\n",
    "ax2.set_ylabel(\"Residuals\")\n",
    "ax2.set_title(\"Residuals vs predicted values - $ AR(5) $ with month\")\n",
    "ax2.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, I also tried to use predict _returns_ instead of volumes using\n",
    "only the previous $ 5 $ days' returns as predictors, or these returns plus the\n",
    "month, but both models result in negative test $ R^2 $, meaning that we could do\n",
    "better simply by predicting the mean of the test data.  This illustrates how\n",
    "hard it is to outperform the total stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
